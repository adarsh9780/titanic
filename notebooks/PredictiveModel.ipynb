{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Author : Adarsh Maurya\n",
    "Email  : adarshmaurya7@gmail.com\n",
    "Project: Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = os.path.join(os.pardir, 'data', 'processed')\n",
    "\n",
    "train_data = os.path.join(processed_data_path, 'train.csv',)\n",
    "test_data = os.path.join(processed_data_path, 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Respecetive Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data, index_col=\"PassengerId\")\n",
    "test_df = pd.read_csv(test_data, index_col=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 24 columns):\n",
      "Unnamed: 0                 891 non-null int64\n",
      "Age                        891 non-null float64\n",
      "Fare                       891 non-null float64\n",
      "isMother                   891 non-null int64\n",
      "FamilySize                 891 non-null int64\n",
      "IsMale                     891 non-null int64\n",
      "Pclass_1                   891 non-null int64\n",
      "Pclass_2                   891 non-null int64\n",
      "Pclass_3                   891 non-null int64\n",
      "Title_Master               891 non-null int64\n",
      "Title_Miss                 891 non-null int64\n",
      "Title_Mr                   891 non-null int64\n",
      "Title_Mrs                  891 non-null int64\n",
      "Title_Sir                  891 non-null int64\n",
      "Fare_Bin_very low          891 non-null int64\n",
      "Fare_Bin_low               891 non-null int64\n",
      "Fare_Bin_high              891 non-null int64\n",
      "Fare_Bin_extremely high    891 non-null int64\n",
      "Embarked_C                 891 non-null int64\n",
      "Embarked_Q                 891 non-null int64\n",
      "Embarked_S                 891 non-null int64\n",
      "AgeState_Adult             891 non-null int64\n",
      "AgeState_Child             891 non-null int64\n",
      "Survived                   891 non-null int64\n",
      "dtypes: float64(2), int64(22)\n",
      "memory usage: 174.0 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 23 columns):\n",
      "Unnamed: 0                 418 non-null int64\n",
      "Age                        418 non-null float64\n",
      "Fare                       418 non-null float64\n",
      "isMother                   418 non-null int64\n",
      "FamilySize                 418 non-null int64\n",
      "IsMale                     418 non-null int64\n",
      "Pclass_1                   418 non-null int64\n",
      "Pclass_2                   418 non-null int64\n",
      "Pclass_3                   418 non-null int64\n",
      "Title_Master               418 non-null int64\n",
      "Title_Miss                 418 non-null int64\n",
      "Title_Mr                   418 non-null int64\n",
      "Title_Mrs                  418 non-null int64\n",
      "Title_Sir                  418 non-null int64\n",
      "Fare_Bin_very low          418 non-null int64\n",
      "Fare_Bin_low               418 non-null int64\n",
      "Fare_Bin_high              418 non-null int64\n",
      "Fare_Bin_extremely high    418 non-null int64\n",
      "Embarked_C                 418 non-null int64\n",
      "Embarked_Q                 418 non-null int64\n",
      "Embarked_S                 418 non-null int64\n",
      "AgeState_Adult             418 non-null int64\n",
      "AgeState_Child             418 non-null int64\n",
      "dtypes: float64(2), int64(21)\n",
      "memory usage: 78.4 KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare two arrays, one input array X and one output array Y\n",
    "# unlike python SLICES, PANDAS SLICES include BOTH [start:End]\n",
    "# USE UPPERCASE FOR MATRIX & LOWERCASE FOR VECTOR\n",
    "X = train_df.loc[:, :\"AgeState_Child\"].as_matrix().astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ravel is numpy function which converts it into 1-dimensional array\n",
    "y = train_df.Survived.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:(891, 23)    Shape of y:(891,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:{}    Shape of y:{}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 23) (712,) (179, 23) (179,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y test mean 0.3854748603351955\n",
      "Y train mean 0.38342696629213485\n"
     ]
    }
   ],
   "source": [
    "# our train data must be balanced i.e 50% +ve value, 50% -ve value\n",
    "# even some time this is not possible, but it must be looked for\n",
    "print(\"Y test mean {}\".format(np.mean(y_test)))\n",
    "print(\"Y train mean {}\".format(np.mean(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dummy = DummyClassifier(strategy=\"most_frequent\", random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=0, strategy='most_frequent')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6145251396648045"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model ACCURACY\n",
    "model_dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Baseline model is : 0.6145251396648045\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Baseline model is : {}\".format(accuracy_score(y_test, model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Baseline model is : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adarsh/miniconda3/envs/DataScience/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision of Baseline model is : {}\".format(precision_score(y_test, model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of Baseline model is : 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall of Baseline model is : {}\".format(recall_score(y_test, model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Baseline model is : [[110   0]\n",
      " [ 69   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix of Baseline model is : {}\".format(confusion_matrix(y_test, model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_df.as_matrix().astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = model_dummy.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame({'PassengerId':test_df.index, 'Survived': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_path = os.path.join(os.pardir, \"data\", \"external\")\n",
    "submit_file_path = os.path.join(submit_path, '01_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=False --> so that no extra column is added\n",
    "df_submit.to_csv(submit_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_file(model, filename):\n",
    "    # create a test matrix with float values\n",
    "    test_X = test_df.as_matrix().astype(\"float\")\n",
    "    print(test_X.shape)\n",
    "    # make prediction on the model\n",
    "    predictions = model.predict(test_X)\n",
    "    # create a dataframe to submit\n",
    "    df_submit = pd.DataFrame({'PassengerId':test_df.index, 'Survived': predictions})\n",
    "    # define submit path and save the data frame in csv format\n",
    "    submit_path = os.path.join(os.pardir, \"data\", \"external\")\n",
    "    submit_file_path = os.path.join(submit_path, filename)\n",
    "    # index=False --> so that no extra column is added\n",
    "    df_submit.to_csv(submit_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 23)\n"
     ]
    }
   ],
   "source": [
    "get_submission_file(model_dummy, '01_submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic model is : 0.8268156424581006\n",
      "Confusion Matrix of Logistic model is : [[95 15]\n",
      " [16 53]]\n",
      "Recall of Logistic model is : 0.7681159420289855\n",
      "Precision of Logistic model is : 0.7794117647058824\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score of Logistic model is : {}\".format(accuracy_score(y_test, model_LR.predict(X_test))))\n",
    "print(\"Confusion Matrix of Logistic model is : {}\".format(confusion_matrix(y_test, model_LR.predict(X_test))))\n",
    "print(\"Recall of Logistic model is : {}\".format(recall_score(y_test, model_LR.predict(X_test))))\n",
    "print(\"Precision of Logistic model is : {}\".format(precision_score(y_test, model_LR.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.81650586e-06, -2.49307794e-02,  2.96493024e-03,\n",
       "         6.87694671e-01, -5.14981444e-01, -1.01230613e+00,\n",
       "         1.17542227e+00,  3.78734185e-01, -4.84481717e-01,\n",
       "         1.41459002e+00,  5.24768134e-01, -1.33632325e+00,\n",
       "         9.07403321e-01, -4.40763490e-01,  8.45987132e-02,\n",
       "         2.33569140e-01,  2.72189689e-01,  4.79317191e-01,\n",
       "         4.57001852e-01,  4.67327840e-01,  1.45345042e-01,\n",
       "         3.41361619e-01,  7.28313115e-01]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model coefficients\n",
    "model_LR.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# you can see that there are 22 coefficients and we had passed 22 parameters\n",
    "print(len(model_LR.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 23)\n"
     ]
    }
   ],
   "source": [
    "get_submission_file(model_LR, '02_LR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
